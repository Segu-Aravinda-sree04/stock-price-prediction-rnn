# -*- coding: utf-8 -*-
"""RNN FINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vVLyVRixAssR9oRRGQ5Q-Yd0tuZRfY-B
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout

# Load data
df = pd.read_csv('NSE-Tata-Global-Beverages-Limited.csv')

# Select relevant columns (assuming the CSV has 'Date' and 'Close' columns)
df = df[['Date', 'Close']]
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)

# Visualize the closing price history
plt.figure(figsize=(16, 8))
plt.plot(df['Close'], label='Close Price History')
plt.show()

# Prepare the dataset
dataset = df.values
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(dataset)

# Define the time step
time_step = 60
X_train, y_train = [], []
for i in range(time_step, len(scaled_data)):
    X_train.append(scaled_data[i-time_step:i, 0])
    y_train.append(scaled_data[i, 0])

X_train, y_train = np.array(X_train), np.array(y_train)
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))

# Initialize the RNN
model = Sequential()

# Add the first LSTM layer and Dropout regularization
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(Dropout(0.2))

# Add the second LSTM layer and Dropout regularization
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))

# Add the third LSTM layer and Dropout regularization
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))

# Add the fourth LSTM layer and Dropout regularization
model.add(LSTM(units=50))
model.add(Dropout(0.2))

# Add the output layer
model.add(Dense(units=1))

# Compile the RNN
model.compile(optimizer='adam', loss='mean_squared_error')

model.fit(X_train, y_train, epochs=100, batch_size=32)

# Load test data (you can split the original dataset or use a separate file)
test_data = df[-80:].values  # For example, use the last 80 records for testing

# Scale the test data
scaled_test_data = scaler.transform(test_data)

# Prepare the input data for prediction
X_test = []
for i in range(time_step, len(scaled_test_data)):
    X_test.append(scaled_test_data[i-time_step:i, 0])

X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Make predictions
predicted_stock_price = model.predict(X_test)
predicted_stock_price = scaler.inverse_transform(predicted_stock_price)

# Visualize the results
plt.figure(figsize=(16, 8))
# Adjust the slicing of test_data to match the number of dates
plt.plot(df.index[-80 + time_step:], test_data[time_step:, 0], color='red', label='Real Stock Price') # Start from the correct index to match the length of test data after time_step
plt.plot(df.index[-80 + time_step:], predicted_stock_price, color='blue', label='Predicted Stock Price') # Adjust the x-axis for predicted values as well
plt.title('Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_error
import math

# Assuming you have already made predictions
# predicted_stock_price = model.predict(X_test)
# predicted_stock_price = scaler.inverse_transform(predicted_stock_price)

# Real stock prices (corresponding to the same period as the test set)
real_stock_price = test_data[time_step:]

# Calculate Mean Squared Error (MSE)
mse = mean_squared_error(real_stock_price, predicted_stock_price)
print(f'Mean Squared Error: {mse}')

# Calculate Root Mean Squared Error (RMSE)
rmse = math.sqrt(mse)
print(f'Root Mean Squared Error: {rmse}')

# Calculate Mean Absolute Error (MAE)
mae = mean_absolute_error(real_stock_price, predicted_stock_price)
print(f'Mean Absolute Error: {mae}')

# Calculate Mean Absolute Percentage Error (MAPE)
mape = np.mean(np.abs((real_stock_price - predicted_stock_price) / real_stock_price)) * 100
print(f'Mean Absolute Percentage Error: {mape}%')

from sklearn.metrics import r2_score
# Calculate the R^2 score
r2 = r2_score(real_stock_price, predicted_stock_price)
print(f'R^2 Score: {r2}')

# Calculate Mean Absolute Percentage Error (MAPE)
mape = np.mean(np.abs((real_stock_price - predicted_stock_price) / real_stock_price)) * 100
print(f'MAPE: {mape}%')

# Calculate total accuracy as (1 - MAPE)
total_accuracy = 100 - mape
print(f'Total Accuracy: {total_accuracy}%')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Load dataset
df = pd.read_csv('NSE-Tata-Global-Beverages-Limited.csv')
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)
data = df['Close'].values.reshape(-1, 1)

# Visualize the closing price history
plt.figure(figsize=(16, 8))
plt.plot(df['Close'], label='Close Price History')
plt.show()

real_stock_price = test_data[time_step:]
# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Create dataset for LSTM
def create_dataset(data, time_step=1):
    X, y = [], []
    for i in range(len(data) - time_step - 1):
        X.append(data[i:(i + time_step), 0])
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

time_step = 60
X, y = create_dataset(scaled_data, time_step)
X = X.reshape(X.shape[0], X.shape[1], 1)

# Build and train the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(X, y, epochs=10, batch_size=32, validation_split=0.1)

# Make predictions
predicted_data = model.predict(X)
predicted_data = scaler.inverse_transform(predicted_data)

# Inverse transform the y values
y_actual = scaler.inverse_transform(y.reshape(-1, 1))

# Calculate metrics
mae = mean_absolute_error(y_actual, predicted_data)
mse = mean_squared_error(y_actual, predicted_data)
rmse = np.sqrt(mse)
r2 = r2_score(y_actual, predicted_data)
mape = np.mean(np.abs((real_stock_price - predicted_stock_price) / real_stock_price)) * 100
total_accuracy = 100 - mape

# Print metrics
print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2): {r2}")
print(f'MAPE: {mape}%')
print(f'Total Accuracy: {total_accuracy}%')

# Plot predictions
plt.figure(figsize=(14, 5))
plt.plot(data, label='Actual Data')
plt.plot(range(time_step + 1, len(predicted_data) + time_step + 1), predicted_data, label='Predicted Data')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Load dataset
df = pd.read_csv('zomato.csv')
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)
data = df['Close'].values.reshape(-1, 1)

real_stock_price = test_data[time_step:]
# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Create dataset for LSTM
def create_dataset(data, time_step=1):
    X, y = [], []
    for i in range(len(data) - time_step - 1):
        X.append(data[i:(i + time_step), 0])
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

time_step = 60
X, y = create_dataset(scaled_data, time_step)
X = X.reshape(X.shape[0], X.shape[1], 1)

# Build and train the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(X, y, epochs=10, batch_size=32, validation_split=0.1)

# Make predictions
predicted_data = model.predict(X)
predicted_data = scaler.inverse_transform(predicted_data)

# Inverse transform the y values
y_actual = scaler.inverse_transform(y.reshape(-1, 1))

# Calculate metrics
mae = mean_absolute_error(y_actual, predicted_data)
mse = mean_squared_error(y_actual, predicted_data)
rmse = np.sqrt(mse)
r2 = r2_score(y_actual, predicted_data)

# Ensure test_data is populated correctly
# For demonstration, let's assume the last 25% of the data is the test set
test_data = scaled_data[int(len(scaled_data) * 0.75):]

real_stock_price = scaler.inverse_transform(test_data[time_step:])

# ... (rest of the code)

mape = np.mean(np.abs((real_stock_price - predicted_data[-len(real_stock_price):]) / real_stock_price)) * 100  # Adjust predicted_data to match the length of real_stock_price

# ... (remaining code)
total_accuracy = 100 - mape

# Print metrics
print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2): {r2}")
print(f'MAPE: {mape}%')
print(f'Total Accuracy: {total_accuracy}%')

# Plot predictions
plt.figure(figsize=(14, 5))
plt.plot(data, label='Actual Data')
plt.plot(range(time_step + 1, len(predicted_data) + time_step + 1), predicted_data, label='Predicted Data')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Load dataset
df = pd.read_csv('NSE-Tata-Global-Beverages-Limited.csv')
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)
data = df['Close'].values.reshape(-1, 1)

# Visualize the closing price history
plt.figure(figsize=(16, 8))
plt.plot(df['Close'], label='Close Price History')
plt.show()

# Normalize the data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data)

# Create dataset for LSTM
def create_dataset(data, time_step=1):
    X, y = [], []
    for i in range(len(data) - time_step - 1):
        X.append(data[i:(i + time_step), 0])
        y.append(data[i + time_step, 0])
    return np.array(X), np.array(y)

time_step = 60
X, y = create_dataset(scaled_data, time_step)
X = X.reshape(X.shape[0], X.shape[1], 1)

# Split data into training and testing sets
# Assuming an 80/20 split
split_index = int(len(X) * 0.8)
X_train, X_test = X[:split_index], X[split_index:]
y_train, y_test = y[:split_index], y[split_index:]

# Build and train the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(time_step, 1)))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(1))

model.compile(optimizer='adam', loss='mean_squared_error')
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)

# Make predictions
predicted_data = model.predict(X_test) # Predict on the test data
predicted_data = scaler.inverse_transform(predicted_data)

# Inverse transform the y_test values
y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))

# Calculate metrics
mae = mean_absolute_error(y_test_actual, predicted_data)
mse = mean_squared_error(y_test_actual, predicted_data)
rmse = np.sqrt(mse)
r2 = r2_score(y_test_actual, predicted_data)

# Calculate MAPE and total accuracy
# Note: Handle potential division by zero
epsilon = 1e-10  # Small value to avoid division by zero
mape = np.mean(np.abs((y_test_actual - predicted_data) / (y_test_actual + epsilon))) * 100
total_accuracy = 100 - mape

# Print metrics
print(f"Mean Absolute Error (MAE): {mae}")
print(f"Mean Squared Error (MSE): {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")
print(f"R-squared (R2): {r2}")
print(f'MAPE: {mape}%')
print(f'Total Accuracy: {total_accuracy}%')

# Plot predictions
plt.figure(figsize=(14, 5))
plt.plot(data, label='Actual Data')
plt.plot(range(time_step + 1, len(predicted_data) + time_step + 1), predicted_data, label='Predicted Data')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()